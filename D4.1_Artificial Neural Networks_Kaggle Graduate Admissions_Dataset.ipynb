{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"D4.1_Artificial Neural Networks_Kaggle Graduate Admissions_Dataset.ipynb","provenance":[{"file_id":"1R_i7knNxkFujGj9dpWPHrQt7jAVVuRpa","timestamp":1572527953251}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"_9LIaZ0Lt0ad","colab_type":"text"},"source":["## Artificial Neural Network\n","Context: this dataset is created for prediction of Graduate Admissions from an Indian perspective.\n","Content: the dataset contains several parameters which are considered important during the application for Masters Programs. The parameters included are : 1. GRE Scores ( out of 340 ) 2. TOEFL Scores ( out of 120 ) 3. University Rating ( out of 5 ) 4. Statement of Purpose and Letter of Recommendation Strength ( out of 5 ) 5. Undergraduate GPA ( out of 10 ) 6. Research Experience ( either 0 or 1 ) 7. Chance of Admit ( ranging from 0 to 1 )\n","\n","Reference: Mohan S Acharya, Asfia Armaan, Aneeta S Antony : A Comparison of Regression Models for Prediction of Graduate Admissions, IEEE International Conference on Computational Intelligence in Data Science 2019"]},{"cell_type":"code","metadata":{"id":"tZPkK_xyt0ag","colab_type":"code","colab":{}},"source":["# Import Librairies\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9kc0rmeq31Gq","colab_type":"text"},"source":["### 1) Download the dataset from this link https://www.kaggle.com/mohansacharya/graduate-admissions and put the csv file in the same directory as the current notebook."]},{"cell_type":"code","metadata":{"id":"2uuIMWYJt0ak","colab_type":"code","outputId":"828d2e55-4c7b-4341-dc20-edda4fa00bbd","executionInfo":{"status":"ok","timestamp":1573322427001,"user_tz":-60,"elapsed":1222,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":194}},"source":["df = pd.read_csv(\"./Admission_Predict.csv\")\n","df.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Serial No.</th>\n","      <th>GRE Score</th>\n","      <th>TOEFL Score</th>\n","      <th>University Rating</th>\n","      <th>SOP</th>\n","      <th>LOR</th>\n","      <th>CGPA</th>\n","      <th>Research</th>\n","      <th>Chance of Admit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>337</td>\n","      <td>118</td>\n","      <td>4</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>9.65</td>\n","      <td>1</td>\n","      <td>0.92</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>324</td>\n","      <td>107</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>4.5</td>\n","      <td>8.87</td>\n","      <td>1</td>\n","      <td>0.76</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>316</td>\n","      <td>104</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>8.00</td>\n","      <td>1</td>\n","      <td>0.72</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>322</td>\n","      <td>110</td>\n","      <td>3</td>\n","      <td>3.5</td>\n","      <td>2.5</td>\n","      <td>8.67</td>\n","      <td>1</td>\n","      <td>0.80</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>314</td>\n","      <td>103</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>8.21</td>\n","      <td>0</td>\n","      <td>0.65</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Serial No.  GRE Score  TOEFL Score  ...  CGPA  Research  Chance of Admit \n","0           1        337          118  ...  9.65         1              0.92\n","1           2        324          107  ...  8.87         1              0.76\n","2           3        316          104  ...  8.00         1              0.72\n","3           4        322          110  ...  8.67         1              0.80\n","4           5        314          103  ...  8.21         0              0.65\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"t1889sUG35O9","colab_type":"text"},"source":["### 2) Find the size of the dataset (the number of rows and columns)"]},{"cell_type":"code","metadata":{"id":"gliFsf1Yt0ao","colab_type":"code","outputId":"24fc15ab-4c70-4a5c-cd14-a466a14fb1f3","executionInfo":{"status":"ok","timestamp":1573322427002,"user_tz":-60,"elapsed":1200,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["df.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(400, 9)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"jHr-MMj64CS0","colab_type":"text"},"source":["### 3) df[['A', 'Z']] : returns all the rows and only column A and Z. We call X the input composed of the following columns of the dataset: [\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"LOR \", \"CGPA\", \"Research\"] and y the output (target) composed of one column [\"Chance of Admit \"]. Define X and y. (You can also try slicing, for example df.iloc[:, 2:4])"]},{"cell_type":"code","metadata":{"id":"3sBQ_QLQt0aq","colab_type":"code","outputId":"d021184e-6027-4cc2-f7fc-6f297b42bce9","executionInfo":{"status":"ok","timestamp":1573322427005,"user_tz":-60,"elapsed":1183,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":194}},"source":["X = df[[\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"LOR \", \"CGPA\", \"Research\"]] \n","y = df[[\"Chance of Admit \"]]\n","\n","y.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Chance of Admit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.92</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.76</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.72</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.80</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.65</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Chance of Admit \n","0              0.92\n","1              0.76\n","2              0.72\n","3              0.80\n","4              0.65"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"AL66_scW4LYn","colab_type":"text"},"source":["### 4) X and y are DataFrames, to be used by numpy we have to transform them into arrays: transform X and y into arrays using \".values\""]},{"cell_type":"code","metadata":{"id":"asNgvIBVt0at","colab_type":"code","outputId":"a47997b4-7f94-422d-b843-b0640ff8c76d","executionInfo":{"status":"ok","timestamp":1573322427007,"user_tz":-60,"elapsed":1167,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["X = X.values\n","y = y.values\n","\n","type(y)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"BzaptdwzKIOk","colab_type":"code","outputId":"4ec651e3-3780-44c9-fb6b-b8e1b7206d50","executionInfo":{"status":"ok","timestamp":1573322427008,"user_tz":-60,"elapsed":1154,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["y.T[:,:5]"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.92, 0.76, 0.72, 0.8 , 0.65]])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"3v0RxhAq4RBX","colab_type":"text"},"source":["### 5) Split data into training and testing datas, the training data is used to train the model, and the testing data is used to test: follow this link that will be helpful for you to split the data. https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"]},{"cell_type":"code","metadata":{"id":"az5y3f-It0aw","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cv6Tv1OU4XGz","colab_type":"text"},"source":["### 6) Using the \"print\" function, display all the splitting data: X_train, X_test, y_train, y_test."]},{"cell_type":"code","metadata":{"id":"Z8VFtWluLUwo","colab_type":"code","outputId":"2586024f-5911-4aac-f2d1-5064589e1ab4","executionInfo":{"status":"ok","timestamp":1573322427691,"user_tz":-60,"elapsed":1807,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(\"X_train :\\n\", X_train) \n","print(\"\\nX_test :\\n\", X_test)\n","print(\"\\ny_train :\\n\", y_train.T) \n","print(\"\\ny_test :\\n\", y_test.T)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["X_train :\n"," [[322.   110.     3.   ...   2.5    8.67   1.  ]\n"," [318.   110.     3.   ...   3.     8.8    0.  ]\n"," [340.   120.     5.   ...   4.5    9.91   1.  ]\n"," ...\n"," [306.   105.     2.   ...   3.     8.22   1.  ]\n"," [302.    99.     1.   ...   2.     7.25   0.  ]\n"," [314.   106.     2.   ...   3.5    8.25   0.  ]]\n","\n","X_test :\n"," [[301.   104.     3.     3.5    4.     8.12   1.  ]\n"," [311.   102.     3.     4.5    4.     8.64   1.  ]\n"," [340.   114.     5.     4.     4.     9.6    1.  ]\n"," [325.   108.     4.     4.5    4.     9.06   1.  ]\n"," [301.    97.     2.     3.     3.     7.88   1.  ]\n"," [340.   115.     5.     4.5    4.5    9.45   1.  ]\n"," [297.    96.     2.     2.5    1.5    7.89   0.  ]\n"," [303.    99.     3.     2.     2.5    7.66   0.  ]\n"," [312.   105.     2.     2.     2.5    8.45   0.  ]\n"," [323.   113.     3.     4.     3.     9.32   1.  ]\n"," [323.   108.     3.     3.5    3.     8.6    0.  ]\n"," [334.   116.     4.     4.     3.5    9.54   1.  ]\n"," [316.   102.     3.     2.     3.     7.4    0.  ]\n"," [321.   111.     5.     5.     5.     9.45   1.  ]\n"," [309.   105.     5.     3.5    3.5    8.56   0.  ]\n"," [313.   107.     2.     2.5    2.     8.5    1.  ]\n"," [308.   103.     2.     3.     3.5    8.49   0.  ]\n"," [297.    96.     2.     2.5    2.     7.43   0.  ]\n"," [319.   106.     3.     3.5    2.5    8.33   1.  ]\n"," [335.   117.     5.     5.     5.     9.82   1.  ]\n"," [301.    99.     2.     3.     2.     8.22   0.  ]\n"," [314.   105.     3.     3.5    2.5    8.3    0.  ]\n"," [318.   106.     3.     2.     3.     8.65   0.  ]\n"," [299.    96.     2.     1.5    2.     7.86   0.  ]\n"," [337.   118.     4.     4.5    4.5    9.65   1.  ]\n"," [325.   107.     3.     3.     3.5    9.11   1.  ]\n"," [311.   105.     3.     3.5    3.     8.45   1.  ]\n"," [296.    99.     2.     2.5    2.5    8.03   0.  ]\n"," [308.   103.     2.     2.5    4.     8.36   1.  ]\n"," [326.   112.     3.     3.5    3.     9.05   1.  ]\n"," [324.   110.     3.     3.5    3.5    9.04   1.  ]\n"," [336.   118.     5.     4.5    5.     9.53   1.  ]\n"," [312.   104.     3.     3.5    4.     8.09   0.  ]\n"," [298.    99.     2.     4.     2.     7.6    0.  ]\n"," [312.   107.     2.     2.5    3.5    8.27   0.  ]\n"," [299.   102.     3.     4.     3.5    8.62   0.  ]\n"," [320.   110.     2.     4.     3.5    8.56   0.  ]\n"," [308.   106.     3.     3.     3.     8.24   0.  ]\n"," [306.   106.     2.     2.     2.5    8.14   0.  ]\n"," [332.   118.     2.     4.5    3.5    9.36   1.  ]\n"," [319.   105.     3.     3.     3.5    8.67   1.  ]\n"," [320.   103.     3.     3.     3.     7.7    0.  ]\n"," [327.   112.     3.     3.     3.     8.72   1.  ]\n"," [340.   120.     5.     4.5    4.5    9.6    1.  ]\n"," [320.   110.     5.     5.     4.5    9.22   1.  ]\n"," [324.   110.     4.     4.5    4.     9.15   1.  ]\n"," [339.   116.     4.     4.     3.5    9.8    1.  ]\n"," [305.   107.     2.     2.5    2.5    8.42   0.  ]\n"," [328.   116.     5.     5.     5.     9.5    1.  ]\n"," [323.   113.     4.     4.     4.5    9.23   1.  ]\n"," [329.   114.     5.     4.     5.     9.3    1.  ]\n"," [323.   104.     3.     4.     4.     8.44   1.  ]\n"," [323.   108.     5.     4.     4.     8.74   1.  ]\n"," [332.   118.     5.     5.     5.     9.64   1.  ]\n"," [315.   105.     2.     2.     2.5    7.65   0.  ]\n"," [307.   108.     2.     4.     3.5    7.7    0.  ]\n"," [308.   109.     2.     3.     4.     8.45   0.  ]\n"," [322.   110.     4.     4.     5.     9.13   1.  ]\n"," [300.    97.     2.     3.     3.     8.1    1.  ]\n"," [321.   112.     5.     5.     5.     9.06   1.  ]\n"," [301.   106.     4.     2.5    3.     8.47   0.  ]\n"," [316.   101.     2.     2.5    2.     8.32   1.  ]\n"," [307.   110.     4.     4.     4.5    8.37   0.  ]\n"," [296.    95.     2.     3.     2.     7.54   1.  ]\n"," [312.   105.     2.     2.5    3.     8.12   0.  ]\n"," [327.   103.     3.     4.     4.     8.3    1.  ]\n"," [303.   100.     2.     3.     3.5    8.06   1.  ]\n"," [327.   113.     4.     4.5    5.     9.14   0.  ]\n"," [329.   111.     4.     4.5    4.     9.23   1.  ]\n"," [314.   108.     4.     4.5    4.     9.04   1.  ]\n"," [317.   106.     3.     4.     3.5    8.5    1.  ]\n"," [329.   110.     2.     4.     3.     9.15   1.  ]\n"," [330.   115.     5.     4.5    3.     9.34   1.  ]\n"," [322.   110.     5.     5.     4.     9.1    1.  ]\n"," [296.    97.     2.     1.5    2.     7.8    0.  ]\n"," [316.   105.     3.     3.     3.5    8.73   0.  ]\n"," [312.   110.     2.     3.5    3.     8.53   0.  ]\n"," [301.    98.     1.     2.     3.     8.03   1.  ]\n"," [329.   119.     4.     4.5    4.5    9.16   1.  ]\n"," [313.   109.     3.     4.     3.5    9.     0.  ]]\n","\n","y_train :\n"," [[0.8  0.63 0.97 0.74 0.58 0.56 0.8  0.66 0.93 0.64 0.64 0.83 0.47 0.76\n","  0.71 0.66 0.79 0.78 0.59 0.72 0.71 0.61 0.66 0.61 0.79 0.68 0.62 0.71\n","  0.73 0.62 0.77 0.53 0.56 0.46 0.86 0.48 0.46 0.93 0.74 0.8  0.65 0.68\n","  0.65 0.42 0.97 0.85 0.73 0.75 0.64 0.81 0.84 0.81 0.77 0.82 0.71 0.77\n","  0.82 0.71 0.84 0.8  0.64 0.78 0.56 0.77 0.73 0.94 0.42 0.69 0.78 0.69\n","  0.75 0.71 0.78 0.93 0.52 0.86 0.57 0.96 0.54 0.67 0.38 0.64 0.92 0.64\n","  0.63 0.74 0.47 0.68 0.83 0.71 0.34 0.78 0.61 0.48 0.97 0.63 0.86 0.7\n","  0.68 0.95 0.58 0.8  0.57 0.68 0.57 0.7  0.67 0.74 0.58 0.78 0.64 0.75\n","  0.89 0.72 0.72 0.75 0.94 0.59 0.73 0.65 0.75 0.97 0.8  0.82 0.81 0.92\n","  0.52 0.84 0.81 0.89 0.76 0.62 0.73 0.69 0.71 0.45 0.51 0.7  0.96 0.89\n","  0.91 0.81 0.93 0.76 0.8  0.72 0.73 0.84 0.72 0.69 0.66 0.91 0.86 0.76\n","  0.94 0.68 0.67 0.85 0.56 0.74 0.71 0.78 0.74 0.72 0.54 0.92 0.76 0.91\n","  0.77 0.76 0.79 0.63 0.72 0.58 0.91 0.57 0.55 0.76 0.7  0.84 0.52 0.78\n","  0.88 0.46 0.68 0.92 0.79 0.49 0.75 0.42 0.56 0.6  0.9  0.62 0.72 0.49\n","  0.76 0.63 0.85 0.73 0.65 0.76 0.7  0.71 0.63 0.79 0.96 0.89 0.9  0.93\n","  0.47 0.89 0.91 0.73 0.73 0.79 0.44 0.78 0.73 0.87 0.82 0.67 0.72 0.8\n","  0.54 0.82 0.84 0.5  0.52 0.62 0.61 0.7  0.46 0.74 0.62 0.91 0.67 0.47\n","  0.85 0.66 0.95 0.68 0.77 0.7  0.64 0.86 0.73 0.77 0.72 0.53 0.87 0.85\n","  0.9  0.7  0.9  0.69 0.72 0.76 0.78 0.5  0.57 0.94 0.7  0.38 0.81 0.78\n","  0.49 0.75 0.65 0.62 0.65 0.64 0.52 0.65 0.8  0.77 0.89 0.79 0.62 0.8\n","  0.76 0.7  0.76 0.87 0.88 0.91 0.93 0.65 0.36 0.82 0.47 0.88 0.71 0.7\n","  0.67 0.57 0.89 0.87 0.64 0.59 0.78 0.69 0.79 0.96 0.94 0.81 0.79 0.95\n","  0.66 0.8  0.94 0.94 0.95 0.64 0.93 0.96 0.87 0.72 0.57 0.62]]\n","\n","y_test :\n"," [[0.68 0.68 0.9  0.79 0.44 0.94 0.43 0.36 0.72 0.85 0.45 0.93 0.64 0.93\n","  0.71 0.53 0.66 0.34 0.74 0.96 0.64 0.54 0.71 0.54 0.92 0.84 0.59 0.61\n","  0.7  0.74 0.82 0.94 0.71 0.46 0.69 0.56 0.72 0.58 0.61 0.9  0.73 0.64\n","  0.74 0.94 0.92 0.82 0.96 0.71 0.94 0.89 0.86 0.73 0.81 0.94 0.39 0.48\n","  0.71 0.86 0.65 0.86 0.57 0.61 0.79 0.44 0.64 0.74 0.64 0.83 0.89 0.84\n","  0.75 0.84 0.9  0.88 0.49 0.72 0.64 0.67 0.9  0.79]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4oIRCGvYt0az","colab_type":"text"},"source":["#  Feature scaling\n","####  7) Feature scaling is a method used to standardize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step. https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html. \n","#### Is it useful or not to normalize your features? make normalization on your data"]},{"cell_type":"code","metadata":{"id":"L2Tj0y01t0a0","colab_type":"code","colab":{}},"source":["# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","\n","std_scaler = StandardScaler()\n","X_train = std_scaler.fit_transform(X_train)\n","X_test = std_scaler.transform(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gz3zC7veOAHC","colab_type":"code","outputId":"b8b48fb4-1558-4a0e-a9d9-be7ea84ac2ab","executionInfo":{"status":"ok","timestamp":1573322427694,"user_tz":-60,"elapsed":1778,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(\"\\t\\tX_train & X_test after standard scaling\")\n","print(\"X_train :\\n\", X_train) \n","print(\"\\nX_test :\\n\", X_test)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\t\tX_train & X_test after standard scaling\n","X_train :\n"," [[ 0.45711129  0.42466178 -0.057308   ... -1.05965163  0.13986648\n","   0.92761259]\n"," [ 0.1022887   0.42466178 -0.057308   ... -0.50194025  0.36110014\n","  -1.07803625]\n"," [ 2.05381293  2.08593034  1.6892215  ...  1.17119391  2.25009529\n","   0.92761259]\n"," ...\n"," [-0.96217907 -0.40597251 -0.93057275 ... -0.50194025 -0.62594237\n","   0.92761259]\n"," [-1.31700165 -1.40273364 -1.8038375  ... -1.61736302 -2.27668588\n","  -1.07803625]\n"," [-0.25253389 -0.23984565 -0.93057275 ...  0.05577114 -0.57488845\n","  -1.07803625]]\n","\n","X_test :\n"," [[-1.4057073  -0.57209936 -0.057308    0.12715607  0.61348253 -0.79612211\n","   0.92761259]\n"," [-0.51865083 -0.90435307 -0.057308    1.10763663  0.61348253  0.08881255\n","   0.92761259]\n"," [ 2.05381293  1.0891692   1.6892215   0.61739635  0.61348253  1.72253809\n","   0.92761259]\n"," [ 0.72322823  0.09240806  0.81595675  1.10763663  0.61348253  0.80356748\n","   0.92761259]\n"," [-1.4057073  -1.73498736 -0.93057275 -0.36308421 -0.50194025 -1.2045535\n","   0.92761259]\n"," [ 2.05381293  1.25529606  1.6892215   1.10763663  1.17119391  1.46726848\n","   0.92761259]\n"," [-1.76052989 -1.90111421 -0.93057275 -0.85332449 -2.17507441 -1.18753552\n","  -1.07803625]\n"," [-1.22829601 -1.40273364 -0.057308   -1.34356476 -1.05965163 -1.57894893\n","  -1.07803625]\n"," [-0.42994518 -0.40597251 -0.93057275 -1.34356476 -1.05965163 -0.23452896\n","  -1.07803625]\n"," [ 0.54581693  0.92304235 -0.057308    0.61739635 -0.50194025  1.24603481\n","   0.92761259]\n"," [ 0.54581693  0.09240806 -0.057308    0.12715607 -0.50194025  0.02074066\n","  -1.07803625]\n"," [ 1.52157905  1.42142291  0.81595675  0.61739635  0.05577114  1.62043024\n","   0.92761259]\n"," [-0.07512259 -0.90435307 -0.057308   -1.34356476 -0.50194025 -2.02141626\n","  -1.07803625]\n"," [ 0.36840564  0.59078863  1.6892215   1.59787691  1.7289053   1.46726848\n","   0.92761259]\n"," [-0.69606212 -0.40597251  1.6892215   0.12715607  0.05577114 -0.04733124\n","  -1.07803625]\n"," [-0.34123954 -0.07371879 -0.93057275 -0.85332449 -1.61736302 -0.14943909\n","   0.92761259]\n"," [-0.78476777 -0.73822622 -0.93057275 -0.36308421  0.05577114 -0.16645706\n","  -1.07803625]\n"," [-1.76052989 -1.90111421 -0.93057275 -0.85332449 -1.61736302 -1.97036234\n","  -1.07803625]\n"," [ 0.19099435 -0.23984565 -0.057308    0.12715607 -1.05965163 -0.43874465\n","   0.92761259]\n"," [ 1.6102847   1.58754977  1.6892215   1.59787691  1.7289053   2.09693353\n","   0.92761259]\n"," [-1.4057073  -1.40273364 -0.93057275 -0.36308421 -1.61736302 -0.62594237\n","  -1.07803625]\n"," [-0.25253389 -0.40597251 -0.057308    0.12715607 -1.05965163 -0.48979857\n","  -1.07803625]\n"," [ 0.1022887  -0.23984565 -0.057308   -1.34356476 -0.50194025  0.10583053\n","  -1.07803625]\n"," [-1.58311859 -1.90111421 -0.93057275 -1.83380504 -1.61736302 -1.23858944\n","  -1.07803625]\n"," [ 1.78769599  1.75367663  0.81595675  1.10763663  1.17119391  1.80762796\n","   0.92761259]\n"," [ 0.72322823 -0.07371879 -0.057308   -0.36308421  0.05577114  0.88865735\n","   0.92761259]\n"," [-0.51865083 -0.40597251 -0.057308    0.12715607 -0.50194025 -0.23452896\n","   0.92761259]\n"," [-1.84923554 -1.40273364 -0.93057275 -0.85332449 -1.05965163 -0.94928388\n","  -1.07803625]\n"," [-0.78476777 -0.73822622 -0.93057275 -0.85332449  0.61348253 -0.38769073\n","   0.92761259]\n"," [ 0.81193388  0.75691549 -0.057308    0.12715607 -0.50194025  0.7865495\n","   0.92761259]\n"," [ 0.63452258  0.42466178 -0.057308    0.12715607  0.05577114  0.76953153\n","   0.92761259]\n"," [ 1.69899035  1.75367663  1.6892215   1.10763663  1.7289053   1.60341227\n","   0.92761259]\n"," [-0.42994518 -0.57209936 -0.057308    0.12715607  0.61348253 -0.84717604\n","  -1.07803625]\n"," [-1.67182424 -1.40273364 -0.93057275  0.61739635 -1.61736302 -1.68105678\n","  -1.07803625]\n"," [-0.42994518 -0.07371879 -0.93057275 -0.85332449  0.05577114 -0.5408525\n","  -1.07803625]\n"," [-1.58311859 -0.90435307 -0.057308    0.61739635  0.05577114  0.0547766\n","  -1.07803625]\n"," [ 0.27969999  0.42466178 -0.93057275  0.61739635  0.05577114 -0.04733124\n","  -1.07803625]\n"," [-0.78476777 -0.23984565 -0.057308   -0.36308421 -0.50194025 -0.59190642\n","  -1.07803625]\n"," [-0.96217907 -0.23984565 -0.93057275 -1.34356476 -1.05965163 -0.76208616\n","  -1.07803625]\n"," [ 1.34416776  1.75367663 -0.93057275  1.10763663  0.05577114  1.31410671\n","   0.92761259]\n"," [ 0.19099435 -0.40597251 -0.057308   -0.36308421  0.05577114  0.13986648\n","   0.92761259]\n"," [ 0.27969999 -0.73822622 -0.057308   -0.36308421 -0.50194025 -1.51087703\n","  -1.07803625]\n"," [ 0.90063952  0.75691549 -0.057308   -0.36308421 -0.50194025  0.22495635\n","   0.92761259]\n"," [ 2.05381293  2.08593034  1.6892215   1.10763663  1.17119391  1.72253809\n","   0.92761259]\n"," [ 0.27969999  0.42466178  1.6892215   1.59787691  1.17119391  1.07585507\n","   0.92761259]\n"," [ 0.63452258  0.42466178  0.81595675  1.10763663  0.61348253  0.95672924\n","   0.92761259]\n"," [ 1.96510729  1.42142291  0.81595675  0.61739635  0.05577114  2.06289758\n","   0.92761259]\n"," [-1.05088471 -0.07371879 -0.93057275 -0.85332449 -1.05965163 -0.28558288\n","  -1.07803625]\n"," [ 0.98934517  1.42142291  1.6892215   1.59787691  1.7289053   1.55235835\n","   0.92761259]\n"," [ 0.54581693  0.92304235  0.81595675  0.61739635  1.17119391  1.09287304\n","   0.92761259]\n"," [ 1.07805082  1.0891692   1.6892215   0.61739635  1.7289053   1.21199886\n","   0.92761259]\n"," [ 0.54581693 -0.57209936 -0.057308    0.61739635  0.61348253 -0.25154693\n","   0.92761259]\n"," [ 0.54581693  0.09240806  1.6892215   0.61739635  0.61348253  0.2589923\n","   0.92761259]\n"," [ 1.34416776  1.75367663  1.6892215   1.59787691  1.7289053   1.79060999\n","   0.92761259]\n"," [-0.16382824 -0.40597251 -0.93057275 -1.34356476 -1.05965163 -1.59596691\n","  -1.07803625]\n"," [-0.87347342  0.09240806 -0.93057275  0.61739635  0.05577114 -1.51087703\n","  -1.07803625]\n"," [-0.78476777  0.25853492 -0.93057275 -0.36308421  0.61348253 -0.23452896\n","  -1.07803625]\n"," [ 0.45711129  0.42466178  0.81595675  0.61739635  1.7289053   0.9226933\n","   0.92761259]\n"," [-1.49441295 -1.73498736 -0.93057275 -0.36308421 -0.50194025 -0.83015806\n","   0.92761259]\n"," [ 0.36840564  0.75691549  1.6892215   1.59787691  1.7289053   0.80356748\n","   0.92761259]\n"," [-1.4057073  -0.23984565  0.81595675 -0.85332449 -0.50194025 -0.20049301\n","  -1.07803625]\n"," [-0.07512259 -1.07047993 -0.93057275 -0.85332449 -1.61736302 -0.45576263\n","   0.92761259]\n"," [-0.87347342  0.42466178  0.81595675  0.61739635  1.17119391 -0.37067275\n","  -1.07803625]\n"," [-1.84923554 -2.06724107 -0.93057275 -0.36308421 -1.61736302 -1.78316462\n","   0.92761259]\n"," [-0.42994518 -0.40597251 -0.93057275 -0.85332449 -0.50194025 -0.79612211\n","  -1.07803625]\n"," [ 0.90063952 -0.73822622 -0.057308    0.61739635  0.61348253 -0.48979857\n","   0.92761259]\n"," [-1.22829601 -1.23660679 -0.93057275 -0.36308421  0.05577114 -0.89822996\n","   0.92761259]\n"," [ 0.90063952  0.92304235  0.81595675  1.10763663  1.7289053   0.93971127\n","  -1.07803625]\n"," [ 1.07805082  0.59078863  0.81595675  1.10763663  0.61348253  1.09287304\n","   0.92761259]\n"," [-0.25253389  0.09240806  0.81595675  1.10763663  0.61348253  0.76953153\n","   0.92761259]\n"," [ 0.01358305 -0.23984565 -0.057308    0.61739635  0.05577114 -0.14943909\n","   0.92761259]\n"," [ 1.07805082  0.42466178 -0.93057275  0.61739635 -0.50194025  0.95672924\n","   0.92761259]\n"," [ 1.16675646  1.25529606  1.6892215   1.10763663 -0.50194025  1.28007076\n","   0.92761259]\n"," [ 0.45711129  0.42466178  1.6892215   1.59787691  0.61348253  0.87163937\n","   0.92761259]\n"," [-1.84923554 -1.73498736 -0.93057275 -1.83380504 -1.61736302 -1.34069729\n","  -1.07803625]\n"," [-0.07512259 -0.40597251 -0.057308   -0.36308421  0.05577114  0.24197432\n","  -1.07803625]\n"," [-0.42994518  0.42466178 -0.93057275  0.12715607 -0.50194025 -0.09838516\n","  -1.07803625]\n"," [-1.4057073  -1.5688605  -1.8038375  -1.34356476 -0.50194025 -0.94928388\n","   0.92761259]\n"," [ 1.07805082  1.91980348  0.81595675  1.10763663  1.17119391  0.97374722\n","   0.92761259]\n"," [-0.34123954  0.25853492 -0.057308    0.61739635  0.05577114  0.70145963\n","  -1.07803625]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eRllrtkot0a3","colab_type":"text"},"source":["## Make your first Simple Neural Network also known as Perceptron\n","### 8) The Network is initialized, since we want to construct a very simple Network: following this link https://keras.io/. We will construct hidden layer(In this case 2 hidden layers are sufficients). For documentation about creating  a sequential model please see the tutorial in this link \n","\n","### 9) Compile the model using: model.compile()"]},{"cell_type":"code","metadata":{"id":"r6LHDyHKXbXK","colab_type":"code","outputId":"651d1881-96bb-4ac8-92de-cd5e1e42108a","executionInfo":{"status":"ok","timestamp":1573322429311,"user_tz":-60,"elapsed":3381,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":82}},"source":["# Import Librairies\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"bvyKN-LeXlW5","colab_type":"code","outputId":"e8c499b6-c4e2-4743-f67f-185a76727e78","executionInfo":{"status":"ok","timestamp":1573322429312,"user_tz":-60,"elapsed":3365,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":444}},"source":["# 9-Building a model\n","#Initialization of Network\n","model = Sequential()\n","\n","#defining layers\n","model.add(Dense(16, input_dim = 7))\n","model.add(Activation('relu'))        # First layer\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))      # Output layer\n","\n","# Compile the model\n","model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=0.01), metrics=['mse'])\n","model.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 16)                128       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 16)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 17        \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 1)                 0         \n","=================================================================\n","Total params: 145\n","Trainable params: 145\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uYvRTgPYt0a9","colab_type":"text"},"source":["## Fitting model\n","#### A model that is well-fitted produces more accurate outcomes, a model that is overfitted matches the train data too closely (low train loss, but high test loss), and a model that is underfitted doesn’t match the train data closely enough (high train loss).\n","#### a) An epoch is an iteration over the entire x and y data provided\n","#### b) Batch size = Number of samples per gradient update. The higher the batch size, the more memory space you'll need.\n"]},{"cell_type":"markdown","metadata":{"id":"34V5N_BA4rgm","colab_type":"text"},"source":["### 10) Fit your trained model"]},{"cell_type":"code","metadata":{"id":"N1WntMTCt0a-","colab_type":"code","outputId":"b9e335a7-7f3d-468d-fa25-4edf8933d6ba","executionInfo":{"status":"ok","timestamp":1573322434311,"user_tz":-60,"elapsed":8348,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#10- Fit the model\n","batch_size = 10\n","epochs = 100\n","model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/100\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"," - 1s - loss: 0.0229 - mean_squared_error: 0.0229\n","Epoch 2/100\n"," - 0s - loss: 0.0067 - mean_squared_error: 0.0067\n","Epoch 3/100\n"," - 0s - loss: 0.0053 - mean_squared_error: 0.0053\n","Epoch 4/100\n"," - 0s - loss: 0.0045 - mean_squared_error: 0.0045\n","Epoch 5/100\n"," - 0s - loss: 0.0047 - mean_squared_error: 0.0047\n","Epoch 6/100\n"," - 0s - loss: 0.0044 - mean_squared_error: 0.0044\n","Epoch 7/100\n"," - 0s - loss: 0.0042 - mean_squared_error: 0.0042\n","Epoch 8/100\n"," - 0s - loss: 0.0040 - mean_squared_error: 0.0040\n","Epoch 9/100\n"," - 0s - loss: 0.0040 - mean_squared_error: 0.0040\n","Epoch 10/100\n"," - 0s - loss: 0.0042 - mean_squared_error: 0.0042\n","Epoch 11/100\n"," - 0s - loss: 0.0040 - mean_squared_error: 0.0040\n","Epoch 12/100\n"," - 0s - loss: 0.0039 - mean_squared_error: 0.0039\n","Epoch 13/100\n"," - 0s - loss: 0.0039 - mean_squared_error: 0.0039\n","Epoch 14/100\n"," - 0s - loss: 0.0039 - mean_squared_error: 0.0039\n","Epoch 15/100\n"," - 0s - loss: 0.0038 - mean_squared_error: 0.0038\n","Epoch 16/100\n"," - 0s - loss: 0.0040 - mean_squared_error: 0.0040\n","Epoch 17/100\n"," - 0s - loss: 0.0038 - mean_squared_error: 0.0038\n","Epoch 18/100\n"," - 0s - loss: 0.0037 - mean_squared_error: 0.0037\n","Epoch 19/100\n"," - 0s - loss: 0.0036 - mean_squared_error: 0.0036\n","Epoch 20/100\n"," - 0s - loss: 0.0037 - mean_squared_error: 0.0037\n","Epoch 21/100\n"," - 0s - loss: 0.0040 - mean_squared_error: 0.0040\n","Epoch 22/100\n"," - 0s - loss: 0.0036 - mean_squared_error: 0.0036\n","Epoch 23/100\n"," - 0s - loss: 0.0035 - mean_squared_error: 0.0035\n","Epoch 24/100\n"," - 0s - loss: 0.0034 - mean_squared_error: 0.0034\n","Epoch 25/100\n"," - 0s - loss: 0.0034 - mean_squared_error: 0.0034\n","Epoch 26/100\n"," - 0s - loss: 0.0035 - mean_squared_error: 0.0035\n","Epoch 27/100\n"," - 0s - loss: 0.0034 - mean_squared_error: 0.0034\n","Epoch 28/100\n"," - 0s - loss: 0.0033 - mean_squared_error: 0.0033\n","Epoch 29/100\n"," - 0s - loss: 0.0039 - mean_squared_error: 0.0039\n","Epoch 30/100\n"," - 0s - loss: 0.0036 - mean_squared_error: 0.0036\n","Epoch 31/100\n"," - 0s - loss: 0.0034 - mean_squared_error: 0.0034\n","Epoch 32/100\n"," - 0s - loss: 0.0039 - mean_squared_error: 0.0039\n","Epoch 33/100\n"," - 0s - loss: 0.0034 - mean_squared_error: 0.0034\n","Epoch 34/100\n"," - 0s - loss: 0.0033 - mean_squared_error: 0.0033\n","Epoch 35/100\n"," - 0s - loss: 0.0033 - mean_squared_error: 0.0033\n","Epoch 36/100\n"," - 0s - loss: 0.0034 - mean_squared_error: 0.0034\n","Epoch 37/100\n"," - 0s - loss: 0.0034 - mean_squared_error: 0.0034\n","Epoch 38/100\n"," - 0s - loss: 0.0032 - mean_squared_error: 0.0032\n","Epoch 39/100\n"," - 0s - loss: 0.0039 - mean_squared_error: 0.0039\n","Epoch 40/100\n"," - 0s - loss: 0.0032 - mean_squared_error: 0.0032\n","Epoch 41/100\n"," - 0s - loss: 0.0032 - mean_squared_error: 0.0032\n","Epoch 42/100\n"," - 0s - loss: 0.0031 - mean_squared_error: 0.0031\n","Epoch 43/100\n"," - 0s - loss: 0.0034 - mean_squared_error: 0.0034\n","Epoch 44/100\n"," - 0s - loss: 0.0031 - mean_squared_error: 0.0031\n","Epoch 45/100\n"," - 0s - loss: 0.0032 - mean_squared_error: 0.0032\n","Epoch 46/100\n"," - 0s - loss: 0.0032 - mean_squared_error: 0.0032\n","Epoch 47/100\n"," - 0s - loss: 0.0030 - mean_squared_error: 0.0030\n","Epoch 48/100\n"," - 0s - loss: 0.0032 - mean_squared_error: 0.0032\n","Epoch 49/100\n"," - 0s - loss: 0.0033 - mean_squared_error: 0.0033\n","Epoch 50/100\n"," - 0s - loss: 0.0030 - mean_squared_error: 0.0030\n","Epoch 51/100\n"," - 0s - loss: 0.0030 - mean_squared_error: 0.0030\n","Epoch 52/100\n"," - 0s - loss: 0.0031 - mean_squared_error: 0.0031\n","Epoch 53/100\n"," - 0s - loss: 0.0031 - mean_squared_error: 0.0031\n","Epoch 54/100\n"," - 0s - loss: 0.0031 - mean_squared_error: 0.0031\n","Epoch 55/100\n"," - 0s - loss: 0.0031 - mean_squared_error: 0.0031\n","Epoch 56/100\n"," - 0s - loss: 0.0030 - mean_squared_error: 0.0030\n","Epoch 57/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 58/100\n"," - 0s - loss: 0.0031 - mean_squared_error: 0.0031\n","Epoch 59/100\n"," - 0s - loss: 0.0029 - mean_squared_error: 0.0029\n","Epoch 60/100\n"," - 0s - loss: 0.0029 - mean_squared_error: 0.0029\n","Epoch 61/100\n"," - 0s - loss: 0.0029 - mean_squared_error: 0.0029\n","Epoch 62/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 63/100\n"," - 0s - loss: 0.0029 - mean_squared_error: 0.0029\n","Epoch 64/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 65/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 66/100\n"," - 0s - loss: 0.0029 - mean_squared_error: 0.0029\n","Epoch 67/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 68/100\n"," - 0s - loss: 0.0029 - mean_squared_error: 0.0029\n","Epoch 69/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 70/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 71/100\n"," - 0s - loss: 0.0030 - mean_squared_error: 0.0030\n","Epoch 72/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 73/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 74/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 75/100\n"," - 0s - loss: 0.0029 - mean_squared_error: 0.0029\n","Epoch 76/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 77/100\n"," - 0s - loss: 0.0029 - mean_squared_error: 0.0029\n","Epoch 78/100\n"," - 0s - loss: 0.0026 - mean_squared_error: 0.0026\n","Epoch 79/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 80/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 81/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 82/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 83/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 84/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 85/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 86/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 87/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 88/100\n"," - 0s - loss: 0.0029 - mean_squared_error: 0.0029\n","Epoch 89/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 90/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 91/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 92/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 93/100\n"," - 0s - loss: 0.0029 - mean_squared_error: 0.0029\n","Epoch 94/100\n"," - 0s - loss: 0.0026 - mean_squared_error: 0.0026\n","Epoch 95/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 96/100\n"," - 0s - loss: 0.0026 - mean_squared_error: 0.0026\n","Epoch 97/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 98/100\n"," - 0s - loss: 0.0027 - mean_squared_error: 0.0027\n","Epoch 99/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n","Epoch 100/100\n"," - 0s - loss: 0.0028 - mean_squared_error: 0.0028\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f658ffde358>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"v9vIC7HL4uMA","colab_type":"text"},"source":["### 11) Make a prediction"]},{"cell_type":"code","metadata":{"id":"upK4NS34t0bD","colab_type":"code","outputId":"d520ec30-4646-419e-d5d0-0dabb5e1fc6e","executionInfo":{"status":"ok","timestamp":1573322434313,"user_tz":-60,"elapsed":8335,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["pred_loss, pred_mse = model.evaluate(X_test, y_test)\n","\n","print(\"\\npred_mse : \", pred_mse)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["80/80 [==============================] - 0s 312us/step\n","\n","pred_mse :  0.00758865752723068\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hanNpjqqt0bG","colab_type":"text"},"source":["### 12)Predict if the student with the following informations will be admitted:\n","#### GRE Score: 220,   TOEFL Score: 100, University rating: 2,  SOP: 3.5, LOR: 3, CGPA: 8, Research: 0\n","\n"]},{"cell_type":"code","metadata":{"id":"kdWBhS4Ht0bG","colab_type":"code","outputId":"f28208f0-5b4e-4b0d-eea7-eeeabc67b298","executionInfo":{"status":"ok","timestamp":1573322434315,"user_tz":-60,"elapsed":8322,"user":{"displayName":"Ndèye Maguette MBAYE","photoUrl":"","userId":"01718406775529037435"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["new_input = np.array([[220, 100, 2, 3.5, 3, 8, 0]])\n","y_pred = model.predict(std_scaler.transform(new_input))\n","\n","y_pred"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.52405584]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":17}]}]}